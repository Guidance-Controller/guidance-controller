{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414e9b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9da683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from scipy.stats import ttest_rel, wilcoxon\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "sns.set(style='whitegrid', palette='deep', font_scale=1.2)\n",
    "\n",
    "###########################\n",
    "### Utility Functions #####\n",
    "###########################\n",
    "\n",
    "def load_all_user_trials(baseline_dir):\n",
    "    \"\"\"\n",
    "    Returns: {user_id: [df1, df2, ...]} from a directory of trial .pkl files\n",
    "    Assumes filenames like: {user_id}_P=*,V=*.pkl\n",
    "    \"\"\"\n",
    "    user_trials = defaultdict(list)\n",
    "    for fname in os.listdir(baseline_dir):\n",
    "        if fname.endswith(\".pkl\"):\n",
    "            try:\n",
    "                user_id = fname.split('_')[0]\n",
    "                with open(os.path.join(baseline_dir, fname), 'rb') as f:\n",
    "                    df = pickle.load(f)\n",
    "                    user_trials[user_id].append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {fname}: {e}\")\n",
    "    return user_trials\n",
    "\n",
    "def time_weighted_rmse(error, t):\n",
    "    \"\"\"\n",
    "    TWRMSE where `error_magnitude` is a 1D array of scalar error values.\n",
    "    (e.g., norms of 3D vectors or alignment errors)\n",
    "    \"\"\"\n",
    "    error = np.asarray(error)\n",
    "    t = np.asarray(t)\n",
    "\n",
    "    dt = np.diff(t)\n",
    "    e_sq = error[:-1] ** 2\n",
    "    weighted_sum = np.sum(e_sq * dt)\n",
    "    duration = t[-1] - t[0]\n",
    "    return np.sqrt(weighted_sum / duration)\n",
    "\n",
    "def velocity_alignment_rmse(x_dot, x_dot_ref, t):\n",
    "    x_dot = np.stack(x_dot)        # (N, 3)\n",
    "    x_dot_ref = np.stack(x_dot_ref)\n",
    "\n",
    "    # Normalize vectors to unit length (add small epsilon to avoid /0)\n",
    "    eps = 1e-8\n",
    "    norms = np.linalg.norm(x_dot, axis=1) + eps\n",
    "    norms_ref = np.linalg.norm(x_dot_ref, axis=1) + eps\n",
    "\n",
    "    x_dot_unit = x_dot / norms[:, None]\n",
    "    x_dot_ref_unit = x_dot_ref / norms_ref[:, None]\n",
    "\n",
    "    cos_sim = np.sum(x_dot_unit * x_dot_ref_unit, axis=1)  # dot product along each row\n",
    "    alignment_error = 1 - cos_sim\n",
    "\n",
    "    return time_weighted_rmse(alignment_error, t)\n",
    "\n",
    "def time_weighted_std(error, t):\n",
    "    error = np.asarray(error)\n",
    "    t = np.asarray(t)\n",
    "\n",
    "    dt = np.diff(t)\n",
    "    weights = dt / np.sum(dt)\n",
    "\n",
    "    mu = np.sum(error[:-1] * weights)\n",
    "    var = np.sum(weights * (error[:-1] - mu)**2)\n",
    "    return np.sqrt(var)\n",
    "\n",
    "def compute_metrics(df):\n",
    "    t = df['t']\n",
    "    e_norms = np.linalg.norm(np.stack(df['e']), axis=1)\n",
    "    edot_norms = np.linalg.norm(np.stack(df['e_dot']), axis=1)\n",
    "\n",
    "    return {\n",
    "    'completion_time': t.iloc[-1] - t.iloc[0],\n",
    "    'rmse_position': time_weighted_rmse(e_norms, t),\n",
    "    'rmse_velocity': time_weighted_rmse(edot_norms, t),\n",
    "    'rmse_velocity_alignment': velocity_alignment_rmse(df['x_dot'], df['x_dot_ref'], t),\n",
    "    'std_position': time_weighted_std(e_norms, t),\n",
    "    'std_velocity': time_weighted_std(edot_norms, t),\n",
    "    'std_velocity_alignment': time_weighted_std(1 - np.sum(\n",
    "        (np.stack(df['x_dot']) / (np.linalg.norm(np.stack(df['x_dot']), axis=1, keepdims=True) + 1e-8)) *\n",
    "        (np.stack(df['x_dot_ref']) / (np.linalg.norm(np.stack(df['x_dot_ref']), axis=1, keepdims=True) + 1e-8)),\n",
    "        axis=1\n",
    "    ), t)\n",
    "}\n",
    "\n",
    "def trim_to_first_three_turns(df):\n",
    "    ref = df['ref_going_forward'].astype(int).values\n",
    "    flipped_to_true = []\n",
    "    for i in range(1, len(ref)):\n",
    "        if ref[i-1] == 0 and ref[i] == 1:\n",
    "            flipped_to_true.append(i)\n",
    "            if len(flipped_to_true) == 3:\n",
    "                return df.iloc[:flipped_to_true[-1]]\n",
    "    return df  # not enough turns â†’ return full trial\n",
    "\n",
    "def aggregate_user_metrics(user_id, baseline, trial_dfs):\n",
    "    trimmed = [trim_to_first_three_turns(df) for df in trial_dfs]\n",
    "    per_trial_metrics = [compute_metrics(df) for df in trimmed]\n",
    "    # per_trial_metrics = [\n",
    "    #     m for m in per_trial_metrics\n",
    "    #     if all(np.isscalar(v) and not np.isnan(v) for v in m.values())\n",
    "    # ]\n",
    "\n",
    "    print(f\"\\n--- Trials for User {user_id} | Baseline: {baseline} ---\")\n",
    "    for idx, m in enumerate(per_trial_metrics):\n",
    "        print(f\"  Trial {idx + 1}:\")\n",
    "        print(f\"    Completion Time: {m['completion_time']:.4f} s\")\n",
    "        print(f\"    TWRMSE Position: {m['rmse_position']:.4f} m\")\n",
    "        print(f\"    TWRMSE Velocity: {m['rmse_velocity']:.4f} m/s\")\n",
    "\n",
    "    if len(per_trial_metrics) == 0:\n",
    "        return {k: np.nan for k in ['completion_time', 'rmse_position', 'rmse_velocity']}\n",
    "\n",
    "    agg = {}\n",
    "    for key in per_trial_metrics[0]:\n",
    "        agg[key] = np.mean([m[key] for m in per_trial_metrics])\n",
    "    return agg\n",
    "\n",
    "##########################\n",
    "### Load All Data ########\n",
    "##########################\n",
    "\n",
    "baseline_dirs = {\n",
    "    'Language': '../data/experiments_no_videos/language_only',\n",
    "    'Force': '../data/experiments_no_videos/physical_only',\n",
    "    'Force+Language': '../data/experiments_no_videos/language_and_force'\n",
    "}\n",
    "\n",
    "metrics = [\n",
    "    'completion_time',\n",
    "    'rmse_position', 'rmse_velocity', 'rmse_velocity_alignment',\n",
    "    'std_position', 'std_velocity', 'std_velocity_alignment'\n",
    "]\n",
    "results = {m: {b: [] for b in baseline_dirs} for m in metrics}\n",
    "\n",
    "# Find common users across all baselines\n",
    "all_users = None\n",
    "for baseline, path in baseline_dirs.items():\n",
    "    user_dfs = load_all_user_trials(path)\n",
    "    user_ids = sorted(user_dfs.keys())\n",
    "    if all_users is None:\n",
    "        all_users = set(user_ids)\n",
    "    else:\n",
    "        all_users &= set(user_ids)\n",
    "all_users = sorted(all_users)\n",
    "\n",
    "# Compute aggregated metrics\n",
    "for baseline, path in baseline_dirs.items():\n",
    "    user_dfs = load_all_user_trials(path)\n",
    "    for user_id in all_users:\n",
    "        trial_dfs = user_dfs[user_id]\n",
    "        agg_metrics = aggregate_user_metrics(user_id, baseline, trial_dfs)\n",
    "        for m in metrics:\n",
    "            results[m][baseline].append(agg_metrics[m])\n",
    "\n",
    "###############################\n",
    "### Debug Print Per User #####\n",
    "###############################\n",
    "\n",
    "print(\"\\n=== AGGREGATED METRICS PER USER ===\")\n",
    "for m in metrics:\n",
    "    print(f\"\\n--- {m.upper()} ---\")\n",
    "    print(\"User\\tLanguage\\tForce\\tLanguage+Force\")\n",
    "    for idx, user_id in enumerate(all_users):\n",
    "        lang = results[m]['Language'][idx]\n",
    "        force = results[m]['Force'][idx]\n",
    "        combined = results[m]['Force+Language'][idx]\n",
    "        print(f\"{user_id}\\t{lang:.4f}\\t\\t{force:.4f}\\t\\t{combined:.4f}\")\n",
    "\n",
    "#################################\n",
    "### Hypothesis Tests ############\n",
    "#################################\n",
    "\n",
    "def run_tests(metric_name):\n",
    "    print(f\"\\n=== {metric_name.upper()} ===\")\n",
    "    F = np.array(results[metric_name]['Force'])\n",
    "    L = np.array(results[metric_name]['Language'])\n",
    "    FL = np.array(results[metric_name]['Force+Language'])\n",
    "\n",
    "    def report(test_name, stat, p):\n",
    "        print(f\"{test_name}: stat = {stat:.4f}, p = {p:.4f}\")\n",
    "\n",
    "    t_stat_FL_F, p_FL_F = ttest_rel(FL, F)\n",
    "    t_stat_FL_L, p_FL_L = ttest_rel(FL, L)\n",
    "    p_FL_F_1sided = p_FL_F / 2 if t_stat_FL_F < 0 else 1 - p_FL_F / 2\n",
    "    p_FL_L_1sided = p_FL_L / 2 if t_stat_FL_L < 0 else 1 - p_FL_L / 2\n",
    "\n",
    "    report(\"Paired t-test: F+L < Force\", t_stat_FL_F, p_FL_F_1sided)\n",
    "    report(\"Paired t-test: F+L < Language\", t_stat_FL_L, p_FL_L_1sided)\n",
    "\n",
    "    w_stat_FL_F, w_p_FL_F = wilcoxon(FL, F, alternative='less')\n",
    "    w_stat_FL_L, w_p_FL_L = wilcoxon(FL, L, alternative='less')\n",
    "\n",
    "    report(\"Wilcoxon: F+L < Force\", w_stat_FL_F, w_p_FL_F)\n",
    "    report(\"Wilcoxon: F+L < Language\", w_stat_FL_L, w_p_FL_L)\n",
    "\n",
    "for m in metrics:\n",
    "    run_tests(m)\n",
    "\n",
    "########################################\n",
    "### Publication-Quality Bar Plots #####\n",
    "########################################\n",
    "\n",
    "def plot_bar(metric_name, use_median=False, show=\"std\"):\n",
    "    \"\"\"\n",
    "    show = 'std', 'iqr', or 'ci'\n",
    "    \"\"\"\n",
    "    data = results[metric_name]\n",
    "\n",
    "    # Display-friendly labels\n",
    "    baseline_labels = {\n",
    "        'Language': 'Language',\n",
    "        'Force': 'Force',\n",
    "        'Force+Language': 'Language+Force'\n",
    "    }\n",
    "\n",
    "    ylabels = {\n",
    "        'completion_time': 'Completion Time (s)',\n",
    "        'rmse_position': 'Position TWRMSE (m)',\n",
    "        'rmse_velocity': 'Velocity TWRMSE (m/s)',\n",
    "        'rmse_velocity_alignment': 'Velocity Alignment TWRMSE',\n",
    "        'std_position': 'Position TWSTD (m)',\n",
    "        'std_velocity': 'Velocity TWSTD (m/s)',\n",
    "        'std_velocity_alignment': 'Velocity Alignment TWSTD'\n",
    "    }\n",
    "\n",
    "    titles = {\n",
    "        'completion_time': 'Mean Completion Time Across Users',\n",
    "        'rmse_position': 'Mean Position TWRMSE Across Users',\n",
    "        'rmse_velocity': 'Mean Velocity TWRMSE Across Users',\n",
    "        'rmse_velocity_alignment': 'Mean Velocity Alignment TWRMSE Across Users',\n",
    "        'std_position': 'Mean Position TWSTD Across Users',\n",
    "        'std_velocity': 'Mean Velocity TWSTD Across Users',\n",
    "        'std_velocity_alignment': 'Mean Velocity Alignment TWSTD Across Users'\n",
    "    }\n",
    "\n",
    "    labels = [baseline_labels[k] for k in data.keys()]\n",
    "    values = [np.median(v) if use_median else np.mean(v) for v in data.values()]\n",
    "\n",
    "    if show == 'std':\n",
    "        errors = [np.std(v) for v in data.values()]\n",
    "    elif show == 'iqr':\n",
    "        errors = [np.percentile(v, 75) - np.percentile(v, 25) for v in data.values()]\n",
    "    elif show == 'ci':\n",
    "        from scipy.stats import sem, t\n",
    "        errors = []\n",
    "        for v in data.values():\n",
    "            s = sem(v)\n",
    "            h = s * t.ppf((1 + 0.95) / 2., len(v) - 1)\n",
    "            errors.append(h)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    bars = ax.bar(labels, values, yerr=errors, capsize=8, width=0.5, color='steelblue')\n",
    "\n",
    "    for bar in bars:\n",
    "        bar.set_edgecolor('black')\n",
    "\n",
    "    ax.set_ylabel(ylabels[metric_name], fontsize=13)\n",
    "    ax.set_title(titles[metric_name], fontsize=14)\n",
    "    ax.tick_params(axis='x', labelsize=12)\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "    ax.spines[['top', 'right']].set_visible(False)\n",
    "\n",
    "    # Optionally zoom in on the y-axis for better visual comparison\n",
    "    min_val = min(values)\n",
    "    max_val = max(values)\n",
    "    range_val = max_val - min_val\n",
    "    margin = 0.1 * range_val if range_val > 0 else 0.01  # avoid flat line\n",
    "\n",
    "    # Set limits to zoom in around the range\n",
    "    ax.set_ylim(min_val - margin, max_val + margin)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "##################################\n",
    "### Generate All Plots ###########\n",
    "##################################\n",
    "\n",
    "plot_bar('completion_time', use_median=False, show='std')\n",
    "plot_bar('rmse_position', use_median=False, show='std')\n",
    "plot_bar('std_position', use_median=False, show='std')\n",
    "plot_bar('rmse_velocity', use_median=False, show='std')\n",
    "plot_bar('std_velocity', use_median=False, show='std')\n",
    "plot_bar('rmse_velocity_alignment', use_median=False, show='std')\n",
    "plot_bar('std_velocity_alignment', use_median=False, show='std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec9f1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pickle\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from collections import defaultdict\n",
    "# import warnings\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# sns.set(style='whitegrid', palette='deep', font_scale=1.2)\n",
    "\n",
    "# BASELINE_DIRS = {\n",
    "#     'Language': '../data/experiments_no_videos/language_only',\n",
    "#     'Force': '../data/experiments_no_videos/physical_only',\n",
    "#     'Force+Language': '../data/experiments_no_videos/language_and_force'\n",
    "# }\n",
    "\n",
    "# BEHAVIORAL_CONDITIONS = {\n",
    "#     'Language': ['V=0', 'V=1'],\n",
    "#     'Force': ['P=0', 'P=1'],\n",
    "#     'Force+Language': ['P=0,V=0', 'P=0,V=1', 'P=1,V=0', 'P=1,V=1']\n",
    "# }\n",
    "\n",
    "# METRICS = [\n",
    "#     'completion_time',\n",
    "#     'rmse_position', 'rmse_velocity', 'rmse_velocity_alignment',\n",
    "#     'std_position', 'std_velocity', 'std_velocity_alignment'\n",
    "# ]\n",
    "\n",
    "# def trim_to_first_three_turns(df):\n",
    "#     ref = df['ref_going_forward'].astype(int).values\n",
    "#     flipped = [i for i in range(1, len(ref)) if ref[i-1] == 0 and ref[i] == 1]\n",
    "#     return df.iloc[:flipped[2]] if len(flipped) >= 3 else df\n",
    "\n",
    "# def time_weighted_rmse(error, t):\n",
    "#     error = np.asarray(error)\n",
    "#     t = np.asarray(t)\n",
    "#     dt = np.diff(t)\n",
    "#     e_sq = error[:-1] ** 2\n",
    "#     weighted_sum = np.sum(e_sq * dt)\n",
    "#     return np.sqrt(weighted_sum / (t[-1] - t[0]))\n",
    "\n",
    "# def time_weighted_std(error, t):\n",
    "#     error = np.asarray(error)\n",
    "#     t = np.asarray(t)\n",
    "#     dt = np.diff(t)\n",
    "#     weights = dt / np.sum(dt)\n",
    "#     mu = np.sum(error[:-1] * weights)\n",
    "#     return np.sqrt(np.sum(weights * (error[:-1] - mu)**2))\n",
    "\n",
    "# def velocity_alignment_error(df):\n",
    "#     x_dot = np.stack(df['x_dot'])\n",
    "#     x_dot_ref = np.stack(df['x_dot_ref'])\n",
    "#     eps = 1e-8\n",
    "#     x_unit = x_dot / (np.linalg.norm(x_dot, axis=1, keepdims=True) + eps)\n",
    "#     x_ref_unit = x_dot_ref / (np.linalg.norm(x_dot_ref, axis=1, keepdims=True) + eps)\n",
    "#     return 1 - np.sum(x_unit * x_ref_unit, axis=1)\n",
    "\n",
    "# def compute_metrics(df):\n",
    "#     t = df['t']\n",
    "#     e_norms = np.linalg.norm(np.stack(df['e']), axis=1)\n",
    "#     edot_norms = np.linalg.norm(np.stack(df['e_dot']), axis=1)\n",
    "#     align_err = velocity_alignment_error(df)\n",
    "#     return {\n",
    "#         'completion_time': t.iloc[-1] - t.iloc[0],\n",
    "#         'rmse_position': time_weighted_rmse(e_norms, t),\n",
    "#         'rmse_velocity': time_weighted_rmse(edot_norms, t),\n",
    "#         'rmse_velocity_alignment': time_weighted_rmse(align_err, t),\n",
    "#         'std_position': time_weighted_std(e_norms, t),\n",
    "#         'std_velocity': time_weighted_std(edot_norms, t),\n",
    "#         'std_velocity_alignment': time_weighted_std(align_err, t),\n",
    "#     }\n",
    "\n",
    "# def parse_key(fname):\n",
    "#     parts = fname.split(',')\n",
    "#     p, v = None, None\n",
    "#     for part in parts:\n",
    "#         if 'P=' in part:\n",
    "#             p = int(part.split('=')[1].split('.')[0])\n",
    "#         if 'V=' in part:\n",
    "#             v = int(part.split('=')[1].split('.')[0])\n",
    "#     return p, v\n",
    "\n",
    "# def load_all_trials():\n",
    "#     data = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "#     for baseline, path in BASELINE_DIRS.items():\n",
    "#         for fname in os.listdir(path):\n",
    "#             if '*' in fname or not fname.endswith('.pkl'):\n",
    "#                 continue\n",
    "#             user = fname.split('_')[0]\n",
    "#             p, v = parse_key(fname)\n",
    "#             with open(os.path.join(path, fname), 'rb') as f:\n",
    "#                 df = pickle.load(f)\n",
    "#                 key = []\n",
    "#                 if p is not None:\n",
    "#                     key.append(f'P={p}')\n",
    "#                 if v is not None:\n",
    "#                     key.append(f'V={v}')\n",
    "#                 behavior_key = ','.join(key)\n",
    "#                 data[baseline][behavior_key][user].append(df)\n",
    "#     return data\n",
    "\n",
    "# def aggregate_metrics(data):\n",
    "#     results = defaultdict(lambda: defaultdict(list))\n",
    "#     for baseline in BASELINE_DIRS:\n",
    "#         for behavior in BEHAVIORAL_CONDITIONS[baseline]:\n",
    "#             user_metrics = defaultdict(list)\n",
    "#             for label in data[baseline]:\n",
    "#                 if behavior in label:\n",
    "#                     for user, dfs in data[baseline][label].items():\n",
    "#                         for df in dfs:\n",
    "#                             trimmed = trim_to_first_three_turns(df)\n",
    "#                             m = compute_metrics(trimmed)\n",
    "#                             for k, v in m.items():\n",
    "#                                 user_metrics[k].append(v)\n",
    "#             for k in METRICS:\n",
    "#                 if user_metrics[k]:\n",
    "#                     results[k][f'{baseline}\\n{behavior}'] = user_metrics[k]\n",
    "#     return results\n",
    "\n",
    "# def get_bar_style(label):\n",
    "#     if 'P=1' in label and 'V=1' in label:\n",
    "#         return {'color': 'green', 'hatch': None}\n",
    "#     elif 'P=0' in label and 'V=0' in label:\n",
    "#         return {'color': 'red', 'hatch': None}\n",
    "#     elif ('P=1' in label and 'V=0' in label) or ('P=0' in label and 'V=1' in label):\n",
    "#         return {'color': 'white', 'edgecolor': 'black', 'hatch': 'xx'}\n",
    "#     elif 'P=1' in label or 'V=1' in label:\n",
    "#         return {'color': 'green', 'hatch': None}\n",
    "#     elif 'P=0' in label or 'V=0' in label:\n",
    "#         return {'color': 'red', 'hatch': None}\n",
    "#     else:\n",
    "#         return {'color': 'gray', 'hatch': None}\n",
    "\n",
    "# def plot_metrics(results):\n",
    "#     ylabels = {\n",
    "#         'completion_time': 'Completion Time (s)',\n",
    "#         'rmse_position': 'Position TWRMSE (m)',\n",
    "#         'rmse_velocity': 'Velocity TWRMSE (m/s)',\n",
    "#         'rmse_velocity_alignment': 'Velocity Alignment TWRMSE',\n",
    "#         'std_position': 'Position TWSTD (m)',\n",
    "#         'std_velocity': 'Velocity TWSTD (m/s)',\n",
    "#         'std_velocity_alignment': 'Velocity Alignment TWSTD'\n",
    "#     }\n",
    "\n",
    "#     for metric in METRICS:\n",
    "#         data = results[metric]\n",
    "#         labels = list(data.keys())\n",
    "#         means = [np.mean(data[label]) for label in labels]\n",
    "#         stds = [np.std(data[label]) for label in labels]\n",
    "\n",
    "#         fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "#         for i, (label, mean, std) in enumerate(zip(labels, means, stds)):\n",
    "#             style = get_bar_style(label)\n",
    "#             ax.bar(\n",
    "#                 label, mean, yerr=std, capsize=6, width=0.5,\n",
    "#                 color=style.get('color', 'white'),\n",
    "#                 edgecolor=style.get('edgecolor', 'black'),\n",
    "#                 hatch=style.get('hatch', None)\n",
    "#             )\n",
    "\n",
    "#         ax.set_ylabel(ylabels[metric])\n",
    "#         ax.set_title(f'Mean {ylabels[metric]} Across Users')\n",
    "#         ax.tick_params(axis='x', labelsize=11, rotation=45)\n",
    "#         ax.tick_params(axis='y', labelsize=12)\n",
    "#         ax.spines[['top', 'right']].set_visible(False)\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "\n",
    "# # To use:\n",
    "# trial_data = load_all_trials()\n",
    "# aggregated = aggregate_metrics(trial_data)\n",
    "# plot_metrics(aggregated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guidance-controller",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
