{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c592c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fda0495",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd9ec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Experiment\n",
    "USER_ID = 0\n",
    "\n",
    "# Trajectory Planner\n",
    "REFERENCE_TRAJECTORY_CSV_PATH = '../data/reference_path.csv'\n",
    "INIT_POSE = np.array([-0.68769672,  0.09795882, -0.19265416 + 0.02, -1.16, -1.19, 1.18]) # Also used for Robot\n",
    "\n",
    "# Verbal PD\n",
    "K_v = 12.3 * 2.0\n",
    "B_v = 11.4 * 2.0\n",
    "\n",
    "# F2L\n",
    "T_proj = 4\n",
    "N_proj = 256\n",
    "dt_proj = T_proj / N_proj\n",
    "\n",
    "# Physical Admittance\n",
    "M = 2\n",
    "B = 17.7\n",
    "\n",
    "# F2L\n",
    "F2L_MODEL_PATH = '../data/F2L_models/svm_knn.pkl'\n",
    "FINAL_IMPULSE_THRESHOLD = 0\n",
    "\n",
    "# Real time data collection\n",
    "TABLE_COLUMN_NAMES = [\n",
    "    't',\n",
    "    'x',\n",
    "    'x_dot',\n",
    "    'F_h',\n",
    "    'x_ref',\n",
    "    'x_dot_ref',\n",
    "    'e',\n",
    "    'e_dot',\n",
    "    'P_hat',\n",
    "    'V_hat',\n",
    "    'c_p',\n",
    "    'c_v',\n",
    "    'verbal_P_tracking_term',\n",
    "    'verbal_D_tracking_term',\n",
    "    'verbal_PD_tracking_term',\n",
    "    'U_v',\n",
    "    'physical_P_tracking_term',\n",
    "    'physical_D_tracking_term',\n",
    "    'physical_PD_tracking_term',\n",
    "    'U_p',\n",
    "    'phrase',\n",
    "    'U',\n",
    "    'human_disturbance',\n",
    "    'system_dynamics_input',\n",
    "]\n",
    "DATA_COLLECTION_SAMPLING_RATE = 200\n",
    "\n",
    "# Real time data plotting\n",
    "PLOTTING_SAMPLING_RATE = 30\n",
    "\n",
    "# Robot\n",
    "ROBOT_IP = '169.254.9.43'\n",
    "FORCE_EWMA_TAU = 0.5\n",
    "TRANSLATIONAL_FORCE_DEADBAND = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616fae24",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18575c8e",
   "metadata": {},
   "source": [
    "This baseline is made up of all componentes: Physical PD, Physical Admittance, Verbal PD, Verbal Admittance, F2L, Compliance Estimator, and $J$ Optimization Method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362cf20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timer import Timer\n",
    "from trajectory_planner import TrajectoryPlanner\n",
    "from model import SVMKNNModel\n",
    "import pickle\n",
    "from vocalizer import Vocalizer\n",
    "from virtual_dynamics import SimpleVirtualDynamics\n",
    "from tabular_data_store import TabularDataStore\n",
    "from plot_client import PlotClient\n",
    "from robot import Robot\n",
    "from console_command_thread import ConsoleCommandThread\n",
    "import scipy.stats\n",
    "from phrase_mapping import PHRASE_MAPPING, MEAN_WORDS_PER_PHRASE\n",
    "from camera_feed import CameraFeed\n",
    "from rgbd_stream import RGBDStream_iOS\n",
    "from hand_tracker import HandTracker\n",
    "import random\n",
    "\n",
    "#############\n",
    "### SETUP ###\n",
    "#############\n",
    "\n",
    "### Experiment ###\n",
    "experiment_timer = Timer()\n",
    "\n",
    "### Trajectory Planner ###\n",
    "traj = TrajectoryPlanner(REFERENCE_TRAJECTORY_CSV_PATH, INIT_POSE[:3])\n",
    "\n",
    "### F2L ###\n",
    "with open(F2L_MODEL_PATH, 'rb') as file:\n",
    "    F2L_model: SVMKNNModel = pickle.load(file)\n",
    "phrase = ''\n",
    "voc = Vocalizer()\n",
    "speaking_timer = Timer()\n",
    "\n",
    "### Real time data collection ###\n",
    "table = TabularDataStore(column_names=TABLE_COLUMN_NAMES)\n",
    "table_timer = Timer()\n",
    "\n",
    "### Real time data plotting ###\n",
    "plot = PlotClient()\n",
    "\n",
    "plot.create_plot(\"force_plot\", title=\"Force vs Time\", xlabel=\"Time (s)\", ylabel=\"Force\")\n",
    "plot.create_line(\"force_plot\", \"Fx\", color=\"r\", label=\"Fx\")\n",
    "plot.create_line(\"force_plot\", \"Fy\", color=\"g\", label=\"Fy\")\n",
    "plot.create_line(\"force_plot\", \"Fz\", color=\"b\", label=\"Fz\")\n",
    "\n",
    "plot.create_plot(\"velocity_plot\", title=\"Velocity vs Time\", xlabel=\"Time (s)\", ylabel=\"Velocity\")\n",
    "plot.create_line(\"velocity_plot\", \"vx\", color=\"r\", label=\"vx\")\n",
    "plot.create_line(\"velocity_plot\", \"vy\", color=\"g\", label=\"vy\")\n",
    "plot.create_line(\"velocity_plot\", \"vz\", color=\"b\", label=\"vz\")\n",
    "\n",
    "plot.create_plot(\"error_plot\", title=\"Error vs Time\", xlabel=\"Time (s)\", ylabel=\"Error\")\n",
    "plot.create_line(\"error_plot\", \"ex\", color=\"r\", label=\"ex\")\n",
    "plot.create_line(\"error_plot\", \"ey\", color=\"g\", label=\"ey\")\n",
    "plot.create_line(\"error_plot\", \"ez\", color=\"b\", label=\"ez\")\n",
    "\n",
    "plot.create_plot(\"compliance_plot\", title=\"Estimated Compliance vs Time\", xlabel=\"Time (s)\", ylabel=\"Probability\")\n",
    "plot.create_line(\"compliance_plot\", \"P_hat\", color=\"orange\", label=\"P̂ (Physical)\")\n",
    "plot.create_line(\"compliance_plot\", \"V_hat\", color=\"purple\", label=\"V̂ (Verbal)\")\n",
    " \n",
    "plot.create_plot(\"control_plot\", title=\"Control Inputs vs Time\", xlabel=\"Time (s)\", ylabel=\"Control Norm\")\n",
    "plot.create_line(\"control_plot\", \"U_p\", color=\"cyan\", label=\"‖U_p‖\")\n",
    "plot.create_line(\"control_plot\", \"U_v\", color=\"magenta\", label=\"‖U_v‖\")\n",
    "\n",
    "plot.create_plot(\"U_v_projection_plot\", title=\"Projected U_v Profile\", xlabel=\"Future Steps\", ylabel=\"U_v\")\n",
    "plot.create_line(\"U_v_projection_plot\", \"U_v_x\", color=\"r\", label=\"U_v,x\")\n",
    "plot.create_line(\"U_v_projection_plot\", \"U_v_y\", color=\"g\", label=\"U_v,y\")\n",
    "plot.create_line(\"U_v_projection_plot\", \"U_v_z\", color=\"b\", label=\"U_v,z\")\n",
    "\n",
    "plot_timer = Timer()\n",
    "\n",
    "stream = RGBDStream_iOS()\n",
    "camera_feed = CameraFeed(\"Language Only Experiment\", stream, np.load(\"calibration_matrix.npy\"))\n",
    "hand_tracker = HandTracker()\n",
    "\n",
    "experiment_timer.reset()\n",
    "speaking_timer.reset()\n",
    "\n",
    "x_dot = np.zeros(3)\n",
    "\n",
    "while True:\n",
    "    t = experiment_timer.t()\n",
    "    dt = experiment_timer.dt()\n",
    "\n",
    "    hand_tracker.update(camera_feed.frame)\n",
    "    x = hand_tracker.get_position()\n",
    "    x_dot = x_dot * 0.9 + hand_tracker.get_velocity() * 0.1\n",
    "\n",
    "    ### Trajectory Planner ###\n",
    "    traj.update_reference_trajectory(x)\n",
    "    x_ref, x_dot_ref = traj.get_closest_target(x)\n",
    "\n",
    "    ### Tracking errors ###\n",
    "    e = x_ref - x\n",
    "    e_dot = x_dot_ref - x_dot\n",
    "\n",
    "    ### Verbal PD ###\n",
    "    verbal_P_tracking_term = K_v * e\n",
    "    verbal_D_tracking_term = B_v * e_dot\n",
    "    verbal_PD_tracking_term = verbal_P_tracking_term + verbal_D_tracking_term\n",
    "\n",
    "    ### Verbal Admittance ###\n",
    "    U_v = verbal_PD_tracking_term\n",
    "\n",
    "    ### F2L ###\n",
    "    x_sim = np.copy(x)\n",
    "    x_dot_sim = np.copy(x_dot)\n",
    "\n",
    "    U_v_profile = []\n",
    "\n",
    "    for _ in range(N_proj):\n",
    "        x_ref_proj, x_dot_ref_proj = traj.get_closest_target(x_sim)\n",
    "        \n",
    "        e_proj = x_ref_proj - x_sim\n",
    "        e_dot_proj = x_dot_ref_proj - x_dot_sim\n",
    "\n",
    "        U_v_proj = K_v * e_proj + B_v * e_dot_proj\n",
    "        U_v_profile.append(U_v_proj)\n",
    "\n",
    "        U_proj = U_v_proj\n",
    "\n",
    "        a_proj = (U_proj - B * x_dot_sim) / M\n",
    "        x_dot_sim += a_proj * dt_proj\n",
    "        x_sim += x_dot_sim * dt_proj\n",
    "\n",
    "    U_v_profile = np.array(U_v_profile)\n",
    "    impulse_curve = U_v_profile.cumsum(axis=0) * dt_proj\n",
    "    final_impuse = impulse_curve[-1, :]\n",
    "\n",
    "    speaking_period = MEAN_WORDS_PER_PHRASE / (0.36 * 2.2 ** (2 - 0.0 - 0.0))\n",
    "\n",
    "    if not voc.is_uttering():\n",
    "        if np.linalg.norm(final_impuse) < FINAL_IMPULSE_THRESHOLD or speaking_timer.t() <= speaking_period:\n",
    "            phrase = ''\n",
    "        else:\n",
    "            words = F2L_model.force_to_phrase(impulse_curve[None, :])[0]\n",
    "            phrase = PHRASE_MAPPING[' '.join(words).strip()]\n",
    "            if np.linalg.norm(e) < 2.5 and np.linalg.norm(e_dot) < 0.05:\n",
    "                phrase = random.choice(['good job'])\n",
    "            speaking_timer.reset()\n",
    "\n",
    "    did_utter = voc.utter(phrase)\n",
    "\n",
    "    is_speaking = voc.is_uttering()\n",
    "\n",
    "    ### Real time data collection ###\n",
    "    if table_timer.t() >= DATA_COLLECTION_SAMPLING_RATE**(-1):\n",
    "        table.append_row((\n",
    "            t,\n",
    "            x,\n",
    "            x_dot,\n",
    "            np.nan,\n",
    "            x_ref,\n",
    "            x_dot_ref,\n",
    "            e,\n",
    "            e_dot,\n",
    "            np.nan,\n",
    "            np.nan,\n",
    "            np.nan,\n",
    "            np.nan,\n",
    "            verbal_P_tracking_term,\n",
    "            verbal_D_tracking_term,\n",
    "            verbal_PD_tracking_term,\n",
    "            U_v,\n",
    "            np.nan,\n",
    "            np.nan,\n",
    "            np.nan,\n",
    "            np.nan,\n",
    "            phrase,\n",
    "            np.nan,\n",
    "            np.nan,\n",
    "            np.nan,\n",
    "        ))\n",
    "        \n",
    "        table_timer.reset()\n",
    "        \n",
    "    ### Real time data plotting ###\n",
    "    # if plot_timer.t() >= PLOTTING_SAMPLING_RATE**(-1):\n",
    "    #     # plot.update_line(\"force_plot\", \"Fx\", (t, F_h[0]))\n",
    "    #     # plot.update_line(\"force_plot\", \"Fy\", (t, F_h[1]))\n",
    "    #     # plot.update_line(\"force_plot\", \"Fz\", (t, F_h[2]))\n",
    "\n",
    "    #     plot.update_line(\"velocity_plot\", \"vx\", (t, x_dot[0]))\n",
    "    #     plot.update_line(\"velocity_plot\", \"vy\", (t, x_dot[1]))\n",
    "    #     plot.update_line(\"velocity_plot\", \"vz\", (t, x_dot[2]))\n",
    "\n",
    "    #     plot.update_line(\"error_plot\", \"ex\", (t, e[0]))\n",
    "    #     plot.update_line(\"error_plot\", \"ey\", (t, e[1]))\n",
    "    #     plot.update_line(\"error_plot\", \"ez\", (t, e[2]))\n",
    "\n",
    "    #     # plot.update_line(\"compliance_plot\", \"P_hat\", (t, P_hat))\n",
    "    #     # plot.update_line(\"compliance_plot\", \"V_hat\", (t, V_hat))\n",
    "\n",
    "    #     # plot.update_line(\"control_plot\", \"U_p\", (t, np.linalg.norm(U_p)))\n",
    "    #     plot.update_line(\"control_plot\", \"U_v\", (t, np.linalg.norm(U_v)))\n",
    "\n",
    "    #     timesteps = np.arange(len(U_v_profile)) * dt_proj\n",
    "\n",
    "    #     plot.update_line(\"U_v_projection_plot\", \"proj_v_impulse_x\", (timesteps, impulse_curve[:, 0]), mode=\"replace\")\n",
    "    #     plot.update_line(\"U_v_projection_plot\", \"proj_v_impulse_y\", (timesteps, impulse_curve[:, 1]), mode=\"replace\")\n",
    "    #     plot.update_line(\"U_v_projection_plot\", \"proj_v_impulse_z\", (timesteps, impulse_curve[:, 2]), mode=\"replace\")\n",
    "\n",
    "    #     plot_timer.reset()\n",
    "\n",
    "    camera_feed.draw_world_point(x, radius=max(1, int(5.0 / np.linalg.norm(camera_feed.frame.camera.position - x))), color=(255, 0, 0))\n",
    "    camera_feed.draw_world_arrow(x, x + x_dot, thickness=5, color=(255, 0, 0))\n",
    "    camera_feed.draw_world_point(x_ref, radius=max(1, int(5.0 / np.linalg.norm(camera_feed.frame.camera.position - x_ref))), color=(0, 255, 0))\n",
    "    # for point in traj.positions:\n",
    "    #     camera_feed.draw_world_point(point, radius=max(1, int(5.0 / np.linalg.norm(camera_feed.frame.camera.position - point))), color=(0, 255, 0))\n",
    "    camera_feed.update_window()\n",
    "\n",
    "\n",
    "# table.to_pandas().to_pickle(f'../data/experiments/physical_only/{USER_ID}.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
